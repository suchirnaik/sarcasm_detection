{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d374d1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b2405b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/suchirnaik/Downloads/three_hundred_labeled_samples_suchir.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72fbd750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you ever go to any of the \"Crossroads of th...</td>\n",
       "      <td>Thanks, I've been meaning to go to a gun show,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All 3 services have the medic role you are tal...</td>\n",
       "      <td>Aged care placement and care plans are integra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We were too nice to the south after the war du...</td>\n",
       "      <td>yeah, I'm sure continuing the scorched-earth, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If this offer existed...</td>\n",
       "      <td>Now **that's** a *great* idea!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So I guess this means that even solar power is...</td>\n",
       "      <td>Those birds would have died of thirst anyways.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Trump would have an amazing legacy in my mind ...</td>\n",
       "      <td>Yeah no scientist has ever or will ever be wro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>If you ask my dad, me apparently</td>\n",
       "      <td>:( happy holidays</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>\"Secretary of Health and Human Services sounds...</td>\n",
       "      <td>I mean, how wide is the scope of the president?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Pounds</td>\n",
       "      <td>So $100 bucks ;)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Indeed, remember 3.6% more from BU also means ...</td>\n",
       "      <td>Yeah, that's awesome for Bitcoin, no progress ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        parent_comment  \\\n",
       "0    If you ever go to any of the \"Crossroads of th...   \n",
       "1    All 3 services have the medic role you are tal...   \n",
       "2    We were too nice to the south after the war du...   \n",
       "3                             If this offer existed...   \n",
       "4    So I guess this means that even solar power is...   \n",
       "..                                                 ...   \n",
       "268  Trump would have an amazing legacy in my mind ...   \n",
       "269                   If you ask my dad, me apparently   \n",
       "270  \"Secretary of Health and Human Services sounds...   \n",
       "271                                             Pounds   \n",
       "272  Indeed, remember 3.6% more from BU also means ...   \n",
       "\n",
       "                                               comment  label  \n",
       "0    Thanks, I've been meaning to go to a gun show,...      0  \n",
       "1    Aged care placement and care plans are integra...      0  \n",
       "2    yeah, I'm sure continuing the scorched-earth, ...      1  \n",
       "3                       Now **that's** a *great* idea!      0  \n",
       "4       Those birds would have died of thirst anyways.      1  \n",
       "..                                                 ...    ...  \n",
       "268  Yeah no scientist has ever or will ever be wro...      1  \n",
       "269                                  :( happy holidays      0  \n",
       "270    I mean, how wide is the scope of the president?      1  \n",
       "271                                   So $100 bucks ;)      0  \n",
       "272  Yeah, that's awesome for Bitcoin, no progress ...      0  \n",
       "\n",
       "[273 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e6b3605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    147\n",
       "1    126\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "787bb82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0c3d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined_text'] = df['comment'] + ' ' + df['parent_comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d690b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "# Tokenize the text data\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "encoded_data = tokenizer(df['combined_text'].tolist(), padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "deb041c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your complete DataFrame\n",
    "labels_complete = torch.tensor(df['label'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0720eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(encoded_data['input_ids'], labels_complete , test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f727b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a DataLoader\n",
    "train_dataset = TensorDataset(train_inputs, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be719c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "# Load the pre-trained model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7e4c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88a5cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "929a5683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b647ba1ea844a38b10600c73e3dade7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c47a37600d04744a8e826a034c57b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9809ebbbd6a947de8d116615edac30c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "total_epochs = 5  \n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{total_epochs}\")\n",
    "    \n",
    "    # Use tqdm for a progress bar over the batches\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n",
    "        input_ids, labels = batch\n",
    "        outputs = model(input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dc92025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45454545454545453\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(test_inputs, labels=test_labels)\n",
    "    predicted_labels = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "accuracy = (predicted_labels == test_labels).sum().item() / len(test_labels)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
